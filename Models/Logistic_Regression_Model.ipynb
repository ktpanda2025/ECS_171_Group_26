{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvRHtH1JeKro"
      },
      "source": [
        "I tried testing the different solvers and different Regularization techniques (when applicable) and found that the accuracies are nearly identical and after some research, it seems that the reason the solvers had no effect on the accuracies was likely because our data was not too complicated and linearly separable.\n",
        "\n",
        "However, in terms of how long the model took, the second model, solver='liblinear' penalty='l2' was significantly faster than the other 4 models.\n",
        "\n",
        "Probably best to adjust the class_weight parameter, since there is likely many more instances of Diabetes=0 rather than Diabetes=1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLLSCZ7QUSVB",
        "outputId": "ec925c5f-5f4d-4f57-8dbd-2c6ff1acb499"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model 1 Accuracy: 0.7277\n",
            "\n",
            "Model 2 Accuracy: 0.7277\n",
            "\n",
            "Model 3 Accuracy: 0.7277\n",
            "\n",
            "Model 4 Accuracy: 0.7275\n",
            "\n",
            "Model 5 Accuracy: 0.7277\n"
          ]
        }
      ],
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# I tried testing the different solvers and different Regularization techniques (when applicable) and found that the accuracies are nearly identical\n",
        "# after some research, the reason the solvers had no effect on the accuracies was likely because our data was not too complicated and linearly separable.\n",
        "# However, in terms of how long the model took, the second model, solver='liblinear' penalty='l2' was significantly faster than the other 4 models.\n",
        "\n",
        "# Probably best to adjust the class_weight parameter, since there is likely many more instances of Diabetes=0 rather than\n",
        "\n",
        "# fetch dataset\n",
        "cdc_diabetes_health_indicators = fetch_ucirepo(id=891)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = cdc_diabetes_health_indicators.data.features\n",
        "y = cdc_diabetes_health_indicators.data.targets\n",
        "\n",
        "# create pandas dataframe\n",
        "df = pd.concat([X, y], axis=1)\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "selected_features = [\n",
        "    'HighBP', 'GenHlth', 'DiffWalk', 'BMI', 'HighChol', 'Age',\n",
        "    'PhysHlth', 'HeartDiseaseorAttack', 'NoDocbcCost', 'MentHlth'\n",
        "]\n",
        "X = df[selected_features]\n",
        "y = df['Diabetes_binary']\n",
        "\n",
        "# Split the original data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Going to change around a few of the parameters, namely the solver and the C value for the regularization\n",
        "\n",
        "# Model 1: solver=lbfgs\n",
        "# Initialize the model\n",
        "# This model takes a moderately long time to run\n",
        "log_reg1 = LogisticRegression(\n",
        "    penalty='l2',\n",
        "    C=1.0,\n",
        "    random_state=42,\n",
        "    class_weight='balanced',\n",
        "    solver='lbfgs',\n",
        "    max_iter=1000\n",
        "    )\n",
        "\n",
        "# train the model\n",
        "log_reg1.fit(X_train, y_train)\n",
        "\n",
        "# make predictions\n",
        "y_pred1 = log_reg1.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred1)\n",
        "print(f\"\\nModel 1 Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "# Model 2: solver=liblinear, penalty=l2\n",
        "# Initialize the model\n",
        "# This model is significantly faster than the other models\n",
        "log_reg2 = LogisticRegression(\n",
        "    penalty='l2',\n",
        "    C=1.0,\n",
        "    random_state=42,\n",
        "    class_weight='balanced',\n",
        "    solver='liblinear',\n",
        "    max_iter=1000\n",
        "    )\n",
        "\n",
        "# train the model\n",
        "log_reg2.fit(X_train, y_train)\n",
        "\n",
        "# make predictions\n",
        "y_pred2 = log_reg2.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred2)\n",
        "print(f\"\\nModel 2 Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "# Model 3: solver=liblinear, penalty=l1\n",
        "# Initialize the model\n",
        "# This model is relatively fast compared to other models\n",
        "log_reg3 = LogisticRegression(\n",
        "    penalty='l1',\n",
        "    C=1.0,\n",
        "    random_state=42,\n",
        "    class_weight='balanced',\n",
        "    solver='liblinear',\n",
        "    max_iter=1000\n",
        "    )\n",
        "\n",
        "# train the model\n",
        "log_reg3.fit(X_train, y_train)\n",
        "\n",
        "# make predictions\n",
        "y_pred3 = log_reg3.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred3)\n",
        "print(f\"\\nModel 3 Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "# Model 4: solver=sag, penalty=l2\n",
        "# Initialize the model\n",
        "# This model takes decently long to run\n",
        "log_reg4 = LogisticRegression(\n",
        "    penalty='l2',\n",
        "    C=1.0,\n",
        "    random_state=42,\n",
        "    class_weight='balanced',\n",
        "    solver='sag',\n",
        "    max_iter=1000\n",
        "    )\n",
        "\n",
        "# train the model\n",
        "log_reg4.fit(X_train, y_train)\n",
        "\n",
        "# make predictions\n",
        "y_pred4 = log_reg4.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred4)\n",
        "print(f\"\\nModel 4 Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "# Model 5: solver=saga, penalty=l2\n",
        "# Initialize the model\n",
        "# This model takes significantly longer to run than the rest\n",
        "log_reg5 = LogisticRegression(\n",
        "    penalty='l2',\n",
        "    C=1.0,\n",
        "    class_weight='balanced',\n",
        "    random_state=42,\n",
        "    solver='saga',\n",
        "    max_iter=1000\n",
        "    )\n",
        "\n",
        "# train the model\n",
        "log_reg5.fit(X_train, y_train)\n",
        "\n",
        "# make predictions\n",
        "y_pred5 = log_reg5.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred5)\n",
        "print(f\"\\nModel 5 Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRgedDq7U1Ue",
        "outputId": "2c625427-22b4-4be6-dd4c-e567df1cf25c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diabetes: 35346\n",
            "No Diabetes: 218334\n"
          ]
        }
      ],
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "import pandas as pd\n",
        "\n",
        "# Count the Instances for Diabetes vs No Diabetes\n",
        "\n",
        "# fetch dataset\n",
        "cdc_diabetes_health_indicators = fetch_ucirepo(id=891)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = cdc_diabetes_health_indicators.data.features\n",
        "y = cdc_diabetes_health_indicators.data.targets\n",
        "\n",
        "# create pandas dataframe\n",
        "df = pd.concat([X, y], axis=1)\n",
        "\n",
        "y = df['Diabetes_binary']\n",
        "\n",
        "diabetes=0\n",
        "no_diabetes=0\n",
        "for i in y:\n",
        "  if (i == 0):\n",
        "    no_diabetes = no_diabetes + 1\n",
        "  else:\n",
        "    diabetes = diabetes + 1\n",
        "\n",
        "print(f\"Diabetes: {diabetes}\")\n",
        "print(f\"No Diabetes: {no_diabetes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc5ka2rUefRV"
      },
      "source": [
        "Based on the above results, there seems to be a Diabetes to No Diabetes ratio of 1:6.177 or 1:6. Hence, it could be worth while to try and change the class_weights directly using this ratio and see how this affects model performance. In theory, this should try and hold the Diabetes results in 6x more importance than that of No Diabetes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6C0b4aud59a",
        "outputId": "d2dbb5ba-013c-42cc-f06d-82197c7aab8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model 2 Accuracy: 0.7277\n",
            "\n",
            "Model 2 Accuracy: 0.7325\n"
          ]
        }
      ],
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# We'll use model 2 and keep the weight='balanced' for model 1 as a reference\n",
        "\n",
        "# fetch dataset\n",
        "cdc_diabetes_health_indicators = fetch_ucirepo(id=891)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = cdc_diabetes_health_indicators.data.features\n",
        "y = cdc_diabetes_health_indicators.data.targets\n",
        "\n",
        "# create pandas dataframe\n",
        "df = pd.concat([X, y], axis=1)\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "selected_features = [\n",
        "    'HighBP', 'GenHlth', 'DiffWalk', 'BMI', 'HighChol', 'Age',\n",
        "    'PhysHlth', 'HeartDiseaseorAttack', 'NoDocbcCost', 'MentHlth'\n",
        "]\n",
        "X = df[selected_features]\n",
        "y = df['Diabetes_binary']\n",
        "\n",
        "# Split the original data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Model 1: solver=liblinear, penalty=l2\n",
        "# Initialize the model\n",
        "# Balanced class weights\n",
        "log_reg1 = LogisticRegression(\n",
        "    penalty='l2',\n",
        "    C=1.0,\n",
        "    random_state=42,\n",
        "    class_weight='balanced',\n",
        "    solver='liblinear',\n",
        "    max_iter=1000\n",
        "    )\n",
        "\n",
        "# train the model\n",
        "log_reg1.fit(X_train, y_train)\n",
        "\n",
        "# make predictions\n",
        "y_pred1 = log_reg1.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred1)\n",
        "print(f\"\\nModel 2 Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "# Model 2: solver=liblinear, penalty=l2\n",
        "# Initialize the model\n",
        "# Manually adjust class weights:\n",
        "#   @ 0 refers to No Diabetes\n",
        "#   @ 1 refers to Diabetes\n",
        "#   @ Hence, the class weight should be\n",
        "#     @ class_weight={0: 1, 1: 6}\n",
        "\n",
        "log_reg2 = LogisticRegression(\n",
        "    penalty='l2',\n",
        "    C=1.0,\n",
        "    random_state=42,\n",
        "    class_weight={0: 1, 1: 6},\n",
        "    solver='liblinear',\n",
        "    max_iter=1000\n",
        "    )\n",
        "\n",
        "# train the model\n",
        "log_reg2.fit(X_train, y_train)\n",
        "\n",
        "# make predictions\n",
        "y_pred2 = log_reg2.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred2)\n",
        "print(f\"\\nModel 2 Accuracy: {accuracy:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89XPXvzpf22c"
      },
      "source": [
        "There doesn't seem to be an incredibly high difference in model performance, but it did increase, although it was less than 1%. Next, we can try putting a much larger weight on Diabetes to see how this affects the performance of the model. I did notice that having a ratio of about 1:1 does skyrocket the accuracy, but I think that is because it completely ignores the existence of Diabetes, not that the model is better at predicting if someone has Diabetes or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyJr7UWOgH_8",
        "outputId": "8d33cd30-f241-423a-cc88-4eef7e58c16a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
            "300 fits failed out of a total of 2400.\n",
            "The score on these train-test partitions for these parameters will be set to 0.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "300 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'class_weight' parameter of LogisticRegression must be an instance of 'dict', a str among {'balanced'} or None. Got 'none' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best: 0.863681 using {'C': 0.01, 'class_weight': {0: 1, 1: 1}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.728644 (0.002651) with: {'C': 10, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.728726 (0.002617) with: {'C': 10, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.000000 (0.000000) with: {'C': 10, 'class_weight': 'none', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.000000 (0.000000) with: {'C': 10, 'class_weight': 'none', 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.863094 (0.001163) with: {'C': 10, 'class_weight': {0: 1, 1: 1}, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.863119 (0.001111) with: {'C': 10, 'class_weight': {0: 1, 1: 1}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.846982 (0.001905) with: {'C': 10, 'class_weight': {0: 1, 1: 2}, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.847038 (0.001991) with: {'C': 10, 'class_weight': {0: 1, 1: 2}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.818856 (0.001890) with: {'C': 10, 'class_weight': {0: 1, 1: 3}, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.818776 (0.001963) with: {'C': 10, 'class_weight': {0: 1, 1: 3}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.789405 (0.002148) with: {'C': 10, 'class_weight': {0: 1, 1: 4}, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.789570 (0.002066) with: {'C': 10, 'class_weight': {0: 1, 1: 4}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.760607 (0.002349) with: {'C': 10, 'class_weight': {0: 1, 1: 5}, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.760805 (0.002230) with: {'C': 10, 'class_weight': {0: 1, 1: 5}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.733040 (0.002603) with: {'C': 10, 'class_weight': {0: 1, 1: 6}, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.733068 (0.002766) with: {'C': 10, 'class_weight': {0: 1, 1: 6}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.728621 (0.002704) with: {'C': 1.0, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.728709 (0.002603) with: {'C': 1.0, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.000000 (0.000000) with: {'C': 1.0, 'class_weight': 'none', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.000000 (0.000000) with: {'C': 1.0, 'class_weight': 'none', 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.863156 (0.001115) with: {'C': 1.0, 'class_weight': {0: 1, 1: 1}, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.863145 (0.001105) with: {'C': 1.0, 'class_weight': {0: 1, 1: 1}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.847107 (0.001995) with: {'C': 1.0, 'class_weight': {0: 1, 1: 2}, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.847091 (0.001978) with: {'C': 1.0, 'class_weight': {0: 1, 1: 2}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.818720 (0.001988) with: {'C': 1.0, 'class_weight': {0: 1, 1: 3}, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.818778 (0.001967) with: {'C': 1.0, 'class_weight': {0: 1, 1: 3}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.789399 (0.002217) with: {'C': 1.0, 'class_weight': {0: 1, 1: 4}, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.789571 (0.002070) with: {'C': 1.0, 'class_weight': {0: 1, 1: 4}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.760515 (0.002334) with: {'C': 1.0, 'class_weight': {0: 1, 1: 5}, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.760805 (0.002232) with: {'C': 1.0, 'class_weight': {0: 1, 1: 5}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.733113 (0.002639) with: {'C': 1.0, 'class_weight': {0: 1, 1: 6}, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.733052 (0.002741) with: {'C': 1.0, 'class_weight': {0: 1, 1: 6}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.728633 (0.002625) with: {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.728543 (0.002633) with: {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.000000 (0.000000) with: {'C': 0.1, 'class_weight': 'none', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.000000 (0.000000) with: {'C': 0.1, 'class_weight': 'none', 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.863057 (0.001189) with: {'C': 0.1, 'class_weight': {0: 1, 1: 1}, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.863240 (0.001087) with: {'C': 0.1, 'class_weight': {0: 1, 1: 1}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.847063 (0.001922) with: {'C': 0.1, 'class_weight': {0: 1, 1: 2}, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.847352 (0.002028) with: {'C': 0.1, 'class_weight': {0: 1, 1: 2}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.818811 (0.001923) with: {'C': 0.1, 'class_weight': {0: 1, 1: 3}, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.818940 (0.001912) with: {'C': 0.1, 'class_weight': {0: 1, 1: 3}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.789479 (0.002128) with: {'C': 0.1, 'class_weight': {0: 1, 1: 4}, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.789521 (0.002062) with: {'C': 0.1, 'class_weight': {0: 1, 1: 4}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.760654 (0.002289) with: {'C': 0.1, 'class_weight': {0: 1, 1: 5}, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.760746 (0.002269) with: {'C': 0.1, 'class_weight': {0: 1, 1: 5}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.733026 (0.002675) with: {'C': 0.1, 'class_weight': {0: 1, 1: 6}, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.732880 (0.002665) with: {'C': 0.1, 'class_weight': {0: 1, 1: 6}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.728607 (0.002670) with: {'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.725407 (0.002737) with: {'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.000000 (0.000000) with: {'C': 0.01, 'class_weight': 'none', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.000000 (0.000000) with: {'C': 0.01, 'class_weight': 'none', 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.863175 (0.001099) with: {'C': 0.01, 'class_weight': {0: 1, 1: 1}, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.863681 (0.000960) with: {'C': 0.01, 'class_weight': {0: 1, 1: 1}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.847145 (0.001936) with: {'C': 0.01, 'class_weight': {0: 1, 1: 2}, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.849164 (0.001968) with: {'C': 0.01, 'class_weight': {0: 1, 1: 2}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.818957 (0.001972) with: {'C': 0.01, 'class_weight': {0: 1, 1: 3}, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.820485 (0.002065) with: {'C': 0.01, 'class_weight': {0: 1, 1: 3}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.789516 (0.002094) with: {'C': 0.01, 'class_weight': {0: 1, 1: 4}, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.789588 (0.002214) with: {'C': 0.01, 'class_weight': {0: 1, 1: 4}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.760557 (0.002220) with: {'C': 0.01, 'class_weight': {0: 1, 1: 5}, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.760240 (0.002351) with: {'C': 0.01, 'class_weight': {0: 1, 1: 5}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.733282 (0.002665) with: {'C': 0.01, 'class_weight': {0: 1, 1: 6}, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.731785 (0.002651) with: {'C': 0.01, 'class_weight': {0: 1, 1: 6}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.728885 (0.002795) with: {'C': 0.001, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.705235 (0.002806) with: {'C': 0.001, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.000000 (0.000000) with: {'C': 0.001, 'class_weight': 'none', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.000000 (0.000000) with: {'C': 0.001, 'class_weight': 'none', 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.863258 (0.000966) with: {'C': 0.001, 'class_weight': {0: 1, 1: 1}, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.861291 (0.000716) with: {'C': 0.001, 'class_weight': {0: 1, 1: 1}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.848138 (0.001880) with: {'C': 0.001, 'class_weight': {0: 1, 1: 2}, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.853623 (0.001829) with: {'C': 0.001, 'class_weight': {0: 1, 1: 2}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.820059 (0.002079) with: {'C': 0.001, 'class_weight': {0: 1, 1: 3}, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.827604 (0.002246) with: {'C': 0.001, 'class_weight': {0: 1, 1: 3}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.790295 (0.002222) with: {'C': 0.001, 'class_weight': {0: 1, 1: 4}, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.788583 (0.002364) with: {'C': 0.001, 'class_weight': {0: 1, 1: 4}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.760839 (0.002238) with: {'C': 0.001, 'class_weight': {0: 1, 1: 5}, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.755224 (0.002584) with: {'C': 0.001, 'class_weight': {0: 1, 1: 5}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.733841 (0.002755) with: {'C': 0.001, 'class_weight': {0: 1, 1: 6}, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.719375 (0.002535) with: {'C': 0.001, 'class_weight': {0: 1, 1: 6}, 'penalty': 'l2', 'solver': 'liblinear'}\n"
          ]
        }
      ],
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "# fetch dataset\n",
        "cdc_diabetes_health_indicators = fetch_ucirepo(id=891)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = cdc_diabetes_health_indicators.data.features\n",
        "y = cdc_diabetes_health_indicators.data.targets\n",
        "\n",
        "# create pandas dataframe\n",
        "df = pd.concat([X, y], axis=1)\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "selected_features = [\n",
        "    'HighBP', 'GenHlth', 'DiffWalk', 'BMI', 'HighChol', 'Age',\n",
        "    'PhysHlth', 'HeartDiseaseorAttack', 'NoDocbcCost', 'MentHlth'\n",
        "]\n",
        "X = df[selected_features]\n",
        "y = df['Diabetes_binary']\n",
        "\n",
        "'''\n",
        "# Split the original data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "'''\n",
        "\n",
        "# define models and parameters\n",
        "model = LogisticRegression()\n",
        "solvers = ['lbfgs', 'liblinear']\n",
        "penalty = ['l2']\n",
        "c_values = [10, 1.0, 0.1, 0.01, 0.001]\n",
        "class_weights = ['balanced', 'none', {0:1, 1:1} , {0: 1, 1: 2}, {0: 1, 1: 3}, {0: 1, 1: 4}, {0: 1, 1: 5}, {0: 1, 1: 6}]\n",
        "\n",
        "# define grid search\n",
        "grid = dict(solver=solvers,penalty=penalty,C=c_values, class_weight=class_weights)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(X, y)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RibeMKlxhaXU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
